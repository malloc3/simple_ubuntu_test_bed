#!/bin/bash -l
#SBATCH -J'simple_first_job'            # this names the job
#SBATCH --ntasks=1                      # this sets the number of cores we may use
#SBATCH --nodes=1                       # this setst the number of nodes we will use
#SBATCH -o outlog                       # this will create an output log
#SBATCH -e errLog                       # this will create an error log
#SBATCH -t 00:10:00                     # this sets the MAX time the job will run (hh:mm:ss)
#SBATCH --mail-user=cmallory@ucsb.edu   # This is asking for email updates
#SBATCH --mail-type ALL                 # This will send updates at every step



#We need to set our file path to be where all of our documents are.
# Typically we will submit our slurm.job file from the right directory.  However
# it is probably good to move to the right folder just in case!
run_files_top_directory="/home/cmallory/simple_ubuntu_test_bed"  # This variable can be changed to hold the directory where stuff is!
cd $run_files_top_directory # THis will set the current direcotry to the run_files_top_directory.    

module load anaconda
echo "It should print the working path from the job run file now"
pwd
echo "Finished printing the current path"

sh test_run_file_1.sh # This runs the .sh run file that handles my scripts.  THis ins't totally needed cause at the end of the day the slurm job is functionally the same.  However I think it will help organize my scripts and keep the slurm jobs a bit more simple

/bin/hostname  # This reports what specific node this code is running on!
time mpirun -np $SLURM_NTASKS  ~pcw/vasp # This will report the actual time that was taken to run my script!

